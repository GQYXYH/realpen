# Quanser Qube-Servo 2 (with Vision Input)
The **[Quanser Qube-Servo 2](https://www.quanser.com/products/qube-servo-2/)** is a one input system that can be used to apply various control and learning algorithms. It can either be set up as a rotating disk or as a furuta pendulum (see image). Encoder values of the rotary arm and the pendulum can be measured and a input voltage can be applied. If the pendulum is used the angle of the rotary arm is limited to one turn due to the connection of the encoder.
In order to not damage the hardware limitations on voltage and safety mechanisms have to be implemented in software.

## Hardware Setup

Instructions for a standardized lab environemnt for vision-based experiments on the Furuta Pendulum can be found [here](./hardware_setup/instructions.md).

## Setup and Use of a Python Interface for the Quanser Qube Servo 2
The *Qube-Servo 2* is a furuta pendulum and can be used for various control and learning tasks. One way of communicating with the device is through a Python Interface. Quanser itself does not support a Python interface but Blue River Tech provides one on their [GitHub repository](https://github.com/BlueRiverTech/quanser-openai-driver). This repository is an extension to the development of Blue River Tech. The interface uses the HIL SDK from Quanser and provides an OpenAI Gym like API to communicate with the Qube Servo 2. Furthermore it comes with various implemented controllers and simulations (more of those below). To start with this repository it is recommended to start with the [Blue River Tech repository]((https://github.com/BlueRiverTech/quanser-openai-driver)) and their corresponding [whitepaper](https://arxiv.org/abs/2001.02254) to get an overview of the implemented code.

### Software Setup.
The setup is described in the Blue River Techs GitHub repository and definitely works in Python 3.6.7. Both repositories, the one on GitHub and this one have working ODE simulators but they are different. Both ODE simulation types seem to represent the dynamics of the pendulum and finding a better simulator is a matter of parameter tuning. In addition, this repository includes a new Mujoco simulation. More on the internal simulators can be found below. 

It is recommended to use [conda](https://anaconda.org) as environment and repository management tool.

The naming conventions in the BlueRiverTech repository contradict the ones in their documentation. The naming conventions described here work for the internal repository and are consistent. The GitHub repository is still under development and other useful tools and classes might be available sometime later.

### Prerequisites
#### Driver installation: HIL SDK from Quanser [Hardware only]
If the **hardware version** should be used, the HIL SDK from Quanser must be installed. At the moment, the hardware version of this repository only works on machines with Linux.
A mirror is available at https://github.com/quanser/hil_sdk_linux_x86_64. Follow the instructions there. If you are using a virtual environment (i.e. conda or virtualenv), it is best to install the driver outside even if the installation should not affect the virtual environment directly.

You also must have _pip_ installed (in most cases conda did this already for you so this step might not be needed if conda is used):
```
$ sudo apt-get install python3-pip 
```
This requires a version of the HIL SDK that supports buffer overwrite on overflow (circular buffers). (The mirror posted above supports buffer overflow.)

#### Camera installation: Blackfly Flir

For vison-based hardware experiments the [Flir Blackfly S](https://www.flir.de/products/blackfly-s-usb3/) is required.

Install the non-python [Spinnaker SDK](https://www.flir.de/products/spinnaker-sdk/) and its requirements for connecting to the Blackfly Camera. After that use the whl file provided (Version must match operating system and your Python version!) by running

```
pip install package/blackfly/spinnaker_python-1.23.0.27-cp36-cp36m-linux_x86_64.whl
```

if you use Python 3.6. Alternatively, download the appropriate whl file for your Python version and operating system under https://www.flir.de/products/spinnaker-sdk/.



#### Repository installation
You can install the driver by cloning and pip-installing the repository from above:
```
$ git clone https://git.rwth-aachen.de/dsme/dsme-researcher/emmasgroup/quanser-qube-servo-2-driver.git
$ cd quanser-qube-servo-2-driver
$ pip install -e .
```

If the needed packages are not installed automatically via `setup.py`, install the following also:
```
$ pip install numpy scipy gym matplotlib numba vpython
```

> **Instructions for using Mujoco:** If the Mujoco simulator should be used, the last installation command changes to `$ pip3 install -e . [mujoco]`. [Mujoco](http://www.mujoco.org/index.html) itself should be installed separately and before the installation of this repository since the [mujoco-py](https://github.com/openai/mujoco-py) package relies on an existing installation of Mujoco. Furthermore, [mujoco-py](https://github.com/openai/mujoco-py) only works on Linux and MacOS operating systems.

If the command `pip` is not available try to use `pip3` instead.

> **_Important:_** Every user should adapt the file [`configuration.py`](./gym_brt/data/config/configuration.py) in [`gym_brt/data/config`](./gym_brt/data/config/) to their own needs and must follow the specific ReadMe in this folder.

Once you have that setup: Run `example_code.py` (ensure the *Qube* is connected to your computer). Touch the pendulum if it does not start moving.
```
$ python example_code.py
```

While using the hardware errors can occurs which often can be solved by unplugging the device or restarting the computer.

### Usage
#### OpenAI Gym interface
Usage is very similar to most [OpenAI Gym](https://github.com/openai/gym) environments. Important and different to normal OpenAI Gym is that if you use the hardware classes it requires that you close the environment when finished (See WARNING). This can be done with context managers using a `with` statement:
```python
import gym
from gym_brt.envs import QubeSwingupEnv
from gym_brt.control import QubeFlipUpControl

with QubeSwingupEnv(use_simulator=False, frequency=250) as env:
    controller = QubeFlipUpControl(sample_freq=250, env=env)
    for episode in range(3):
        state = env.reset()
        for step in range(2048):
            action = controller.action(state)
            state, reward, done, info = env.step(action)
```

It can also be closed manually by using explicitly calling `env.close()` in a `try-finally` statement.
 
> **WARNING:** Forgetting to close the environment or incorrectly closing the env leads to several possible issues. The worst including segfaults.
The most common case when the env was not properly closed: you can not reopen the env and you get:

> Error 1073: QERR_BOARD_ALREADY_OPEN: The HIL board is already opened by another process.  The board does not support access from more than one process at the same time.

> The fastest solution (no restart required) is to remove the semaphore of the board:
> 1. Find the location of the semaphore by ls /dev/shm.
>   - It will start with sem.qube_servo2_usb$xxxxxxxxxxxxx (with the 'x's being some alphanumeric sequence).
> 2. Use the rm command to remove it.
>   - Ex: rm /dev/shm/sem.qube_servo2_usb$xxxxxxxxxxxxx

The normal `QubeBaseEnv` should not be initialised solely. There exist multiple subclasses like `QubeSwingupEnv` and `QubeBalanceEnv` that implement specific control problems and their corresponding observation types. Furthermore, this repository contains multiple extensions (wrapper, more subclasses, etc. to change observation type, reward functions and more) which can be found in the directory [gym_brt/envs/reinforcementlearning_extensions](./gym_brt/envs/reinforcementlearning_extensions).

It is recommended to use the `QubeSwingupEnv` or its subclasses since the encoder values of the environment are set to 0 at the beginning which means that either the pendulum in its initial condition is interpreted as a angle of $\pi$ or $0$ respectively. Therefore, inaccuracy in the initial conditions lead to wrong states in the environment. Especially the simulators are just tested for the `QubeSwingupEnv`.

Interacting with the real pendulum or a simulator is nearly identical. The state contains information about the angles of the pendulum alpha and of the rotary arm theta. They can be accessed as following:
```python
theta, alpha, theta_dot, alpha_dot = state
```
The upright equilibrium point is defined as $`\alpha = 0`$ and the downright equilibrium point as $`\alpha = \pm \pi`$ . Looking from the top the positive direction of $`\theta`$ is defined counterclockwise, looking from the front the positive direction of $`\alpha`$ is counterclockwise as well.
The variable `action` refers to the motor voltage and has a limit of $`\pm 18 V`$. This can be additionally limited at 8 V by the environment to prevent hardware damage. 

By manipulating the `use_simulator` variable switching between hardware and simulation can be achieved. The variable `simulation_mode` defines the concrete simulation (i.e. `simulation_mode="mujoco"`).
The two standard controllers (`QubeFlipUpControl`, `QubeHoldControl`) for the pendulum are already implemented in the environment and can be used in a OpenAI Gym style as following:

```python
ctrl_sys = QubeFlipUpControl(env, frequency=frequency)
action = ctrl_sys.action(state)
```

> Usage of the angle $`\alpha`$ is not consistent. Used as above the environment treats $`\alpha = 0`$ as the upward equilibrium point and $`\alpha = \pm \pi`$ as the downward equilibrium point and the implemented controllers use the same convention. Especially if working with the simulator the convention is not guaranteed and the transformation to the encoder values has to be considered.

## Structure
The main part of the repository can be found in the [gym_brt](./gym_brt) directory which includes the OpenAI Gym environments (with the needed data resources), the interface to the hardware and some simple controllers.

The directory [simulator_tuning](./simulator_tuning) contains scripts to optimize the parameters for the different simulations to match their behavior with the hardware.

In [test](./tests) you find simple test scripts and might be a playground to test your implementations.

### Simulator
This repository includes two types of simulators: A simulation calculated with explicit ODEs and simulations which use higher-level software like Mujoco or PyBullet (which also use ODEs but not in such an explicit form). The first type of simulation can be found beside the files of the interface to the hardware version in [gym_brt/quanser/](./gym_brt/quanser). The Mujoco and PyBullet version can be found in the environments directory [gym_brt/envs/simulation](./gym_brt/envs/simulation). The different simulations can be accessed with the constructor arguments `use_simulator` and `simulation_mode` of any Qube instance.

##### ODE
The ODE simulation in [gym_brt/quanser/qube_simulator.py](./gym_brt/quanser/qube_simulator.py) and [gym_brt/quanser/qube_interfaces.py](./gym_brt/quanser/qube_interfaces.py) seems to model the physics quite reasonable but does not provide a precise simulation of the reality. The equations were provided by Peter [peter.martin@quanser.com](peter.martin@quanser.com) from Quanser. They implemented a SIMULINK simulation with a visualization for the Qube Servo2 (accessible in the internal Setup for Matlab/Simulink repository as a zip file: SimulinkSimulationModel_Quanser.zip). The equations seem to be right but the values for the damping coefficients `br` and `bp` had to be negated. Some parameters were tuned heuristically and the simulator is very sensitive to changes in parameters, e.g. the damping coefficients. For further investigation, non-linear and linear modeling approaches for the Furuta pendulum can be found in the [Simulink Courseware on the Quanser website](https://www.quanser.com/products/qube-servo-2/) (dynamic equations contradict each other sometimes, simulator equations in Python and Matlab seem to model the physics quite reasonable).

To get a more precise simulation the parameters have to be adjusted. A team at Bosch invested more time in developing a better physical model, information might be available there.

All simulations can be visualized by using the command `env.render()` in every step but it slows down the simulation noticeably.

##### Mujoco
The Mujoco simulator in [gym_brt/envs/simulation/mujoco/](./gym_brt/envs/simulation/mujoco) uses the Mujoco rigid-body dynamics simulation software to approximate the dynamics of the Qube. This simulation needs an activated [Mujoco installation](http://www.mujoco.org/index.html) and the Python interface [mujoco-py](https://github.com/openai/mujoco-py) from OpenAI. The necessary meshes and configuration files can be found in [gym_brt/data](./gym_brt/data). The simulation works similar to [other robotic environments](https://github.com/openai/gym/tree/master/gym/envs/robotics) of OpenAI Gym.

Since this simulation was build with a simple 3D model provided by Quanser (and not with a CAD model) it is quiet inaccurate as the ODE damping coefficients do not hold anymore and other variables which cannot be measured easily have to be considered additionally (especially the cable influence). Those variables might be tuned by the file [simulator_tuning/simulator_tuning_mujoco.py](./simulator_tuning/simulator_tuning_mujoco.py) if needed and enough time and computational power is available. Further investigation of this problem is definitely needed!

Even if the simulator uses an external software package it is generally faster than the ODE simulation and thus training reinforcement learning agents can be trained with less time. Furthermore rendering is much more realistic than the ODE simulation.

This simulation can be used with the [Simulation Modification Framework]() to apply Domain Randomization. An alternative to this could be OpenAI's [Robogym](https://github.com/openai/robogym) which was not available during the development of the first named framework.

##### PyBullet
A PyBullet simulation is still under development but should be similar to the Mujoco simulation.

##### Other
TBD: Nvidia Isaac, Dart, Unreal + ODE (maybe with help from Quanser)

### Reinforcement Learning Extensions
Extension modules for the `QubeBaseEnv` of the Quanser driver can be found in *[reinforcementlearning_extensions](./gym_brt/envs/reinforcementlearning_extensions)*. The subclasses work as normal OpenAI Gym interfaces like the initially integrated environment classes. I.e. the observed states of the class `QubeBeginDownEnv` are defined as `state = [cos(theta), sin(theta), cos(alpha), sin(alpha), theta_velocity, alpha_velocity]`. 

Furthermore, instead of using subclasses the behavior (observation, reward function, etc.) of an environment can be overwritten with wrapper which should work with most hardware classes and simulated classes (the version where a wrapper does not work should be obvious). Wrapper can be found in _wrapper.py_. Reward functions for this are provided in _rl_reward_functions.py_. 

## Extras
To change the dynamics of the system, additional weights can be applied (currently not at DSME). A setup to to change the orientation of the whole Qube is also available. Both extras are available at MPI in Tuebingen or Stuttgart.

## Contribution
If you contribute to this repository (this means if you change and want to push something which can affect other projects), you should prepare your contribution correctly:

* Code should be consistent so that it works with the simulation and the hardware integrations of the Qube or it should be obvious that the new integration does only work with specific versions.
* It should be clear that your new implementation does not break other code (i.e. if you add an argument to the constructor of the QubeBaseEnv class, this argument should be optional and the behaviour should be the same without your new integration if the argument is not given).
* The Python code conforms to the [PEP8](https://www.python.org/dev/peps/pep-0008/) standard. Please read and understand it in detail.
* Python files should provide docstrings for necessary public methods which follow [PEP257](https://www.python.org/dev/peps/pep-0257/) docstring conventions and [Google](http://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings) docstring formatting. A good docstring example can be found [here](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html).
* Non-Python files (including XML, HTML, CSS, JS, and Shell Scripts) should follow the [Google Style Guide](https://github.com/google/styleguide) for that language. YAML files should use 2 spaces for indentation.
* If possible, integrate tests.
* Remove `print(...)` statements if not needed.
